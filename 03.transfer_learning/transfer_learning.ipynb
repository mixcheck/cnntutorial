{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow-Slim image classification model library\n",
    "\n",
    "git clone https://github.com/tensorflow/models/\n",
    "\n",
    "**TensorFlow-Slim**은 AlexNet, VGG, ResNet, Inception과 같이 image classification에 사용되는 Deep Learning CNN 모델을 제공하고 있다. CNN 모델 뿐만 아니라 여러 Datasets(ImageNet, CIFAR-10, MNIST 등)도 제공하고 있고 이를 이용한 학습 및 실험 코드도 제공하고 있다. 그리고 각 CNN 모델을 ImageNet 데이터로 학습한 Pre-trained 모델도 제공하여 새로운 Datasets에 대한 Fine-tuning도 가능하게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "sys.path.insert(0,'../models/research/slim')\n",
    "from nets import vgg\n",
    "from datasets import cifar10\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "from utils import *\n",
    "from cifar10_loader import CIFAR10_loader\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 Dataset\n",
    "**CIFAR-10** dataset은 32x32 사이즈의 이미지들로 airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck으로 이루어져있다. 각 클래스 별 6천장씩 구성되어 있으며 이중 50000장이 training에 사용되고 10000장이 test에 사용된다. TF-Slim library에서 제공하는 코드를 이용하여 현재 작업중인 폴더의 하위 폴더에 cifar-10 dataset을 저장한다.\n",
    "\n",
    "*CIFAR datasets URL*: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "*CIFAR-10 download link*: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Finished\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd()\n",
    "data_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "maybe_download_and_extract(data_url, data_dir, 'cifar-10-batches')\n",
    "\n",
    "loader = CIFAR10_loader()\n",
    "class_names = loader.get_class_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "VGG network는 입력 영상으로 224x224의 image를 받는다. 이번 실습에서는 **CIFAR-10**을 사용하므로 num_classes를 10으로 정의한다. 매 iteration 마다 100개의 images를 학습시키도록 batch_size를 100으로 한다. 총 epoch은 5회 수행하고, (**CIFAR-10** training data 50000개 기준 약 3시간 소요) 50번의 iteration마다 network의 parameters를 저장한다.\n",
    "\n",
    "learning rate은 초기에 0.001로 정의하고 5 epochs마다 이 값은 1/10로 줄어든다. ImageNet으로 학습된 **VGG-16** network의 parameters는 **vgg_models/vgg_16.ckpt**이다.\n",
    "\n",
    "#### Exercise 1-1\n",
    "학습 횟수 30회, 초기 learning_rate 0.01, 매 10회 학습 마다 learning_rate은 20%로 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 224 # input image size of VGG network\n",
    "num_classes = 10 # CIFAR-10 number of classes\n",
    "batch_size = 100 # number of images per training iteration\n",
    "\n",
    "iteration_per_epoch = int(math.floor(loader.get_num_train_examples() / batch_size))\n",
    "num_epochs = 5 # number of training epoch\n",
    "save_checkpoint_frequency = 500 # frequency of saving checkpoints\n",
    "print_frequency = 10\n",
    "\n",
    "initial_learning_rate = 0.001 # initial learning rate for optimizer\n",
    "num_epochs_before_decay = 5\n",
    "learning_rate_decay_rate = 0.1 # decay rate for learning rate\n",
    "\n",
    "checkpoint_path = 'vgg_models/vgg_16.ckpt' # Pre-trained VGG-16 checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained model (vgg-16)\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/slim\n",
    "\n",
    "TF-Slim github를 보면 ImageNet으로 학습된 Inception, Resnet, VGG 등 다양한 모델들의 checkpoints가 제공된다. 먼저 오늘 실습에 사용될 **VGG-16**의 checkpoint를 다운 받는다.\n",
    "\n",
    "#### Exercise 1-2\n",
    "vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_16/fc8/weights (DT_FLOAT) [1,1,4096,1000]\n",
      "vgg_16/fc7/weights (DT_FLOAT) [1,1,4096,4096]\n",
      "vgg_16/fc7/biases (DT_FLOAT) [4096]\n",
      "vgg_16/fc6/weights (DT_FLOAT) [7,7,512,4096]\n",
      "vgg_16/fc8/biases (DT_FLOAT) [1000]\n",
      "vgg_16/conv5/conv5_2/biases (DT_FLOAT) [512]\n",
      "vgg_16/conv3/conv3_1/biases (DT_FLOAT) [256]\n",
      "vgg_16/conv1/conv1_1/biases (DT_FLOAT) [64]\n",
      "vgg_16/conv5/conv5_3/weights (DT_FLOAT) [3,3,512,512]\n",
      "vgg_16/conv5/conv5_3/biases (DT_FLOAT) [512]\n",
      "vgg_16/conv2/conv2_2/biases (DT_FLOAT) [128]\n",
      "vgg_16/conv1/conv1_2/weights (DT_FLOAT) [3,3,64,64]\n",
      "vgg_16/conv2/conv2_1/biases (DT_FLOAT) [128]\n",
      "vgg_16/conv2/conv2_2/weights (DT_FLOAT) [3,3,128,128]\n",
      "vgg_16/conv1/conv1_2/biases (DT_FLOAT) [64]\n",
      "vgg_16/conv1/conv1_1/weights (DT_FLOAT) [3,3,3,64]\n",
      "vgg_16/conv3/conv3_1/weights (DT_FLOAT) [3,3,128,256]\n",
      "vgg_16/conv2/conv2_1/weights (DT_FLOAT) [3,3,64,128]\n",
      "vgg_16/conv4/conv4_3/weights (DT_FLOAT) [3,3,512,512]\n",
      "vgg_16/conv3/conv3_2/biases (DT_FLOAT) [256]\n",
      "vgg_16/conv5/conv5_1/weights (DT_FLOAT) [3,3,512,512]\n",
      "vgg_16/conv3/conv3_2/weights (DT_FLOAT) [3,3,256,256]\n",
      "vgg_16/conv3/conv3_3/biases (DT_FLOAT) [256]\n",
      "vgg_16/fc6/biases (DT_FLOAT) [4096]\n",
      "vgg_16/conv5/conv5_2/weights (DT_FLOAT) [3,3,512,512]\n",
      "vgg_16/conv3/conv3_3/weights (DT_FLOAT) [3,3,256,256]\n",
      "vgg_16/mean_rgb (DT_FLOAT) [3]\n",
      "vgg_16/conv4/conv4_1/biases (DT_FLOAT) [512]\n",
      "global_step (DT_INT64) []\n",
      "vgg_16/conv4/conv4_1/weights (DT_FLOAT) [3,3,256,512]\n",
      "vgg_16/conv4/conv4_2/biases (DT_FLOAT) [512]\n",
      "vgg_16/conv4/conv4_2/weights (DT_FLOAT) [3,3,512,512]\n",
      "vgg_16/conv4/conv4_3/biases (DT_FLOAT) [512]\n",
      "vgg_16/conv5/conv5_1/biases (DT_FLOAT) [512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'vgg_models'\n",
    "model_url = 'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz'\n",
    "maybe_download_and_extract(model_url, model_dir, 'vgg_16.ckpt')\n",
    "\n",
    "print_tensors_in_checkpoint_file(file_name=checkpoint_path, tensor_name='', all_tensors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vgg-16 Model\n",
    "\n",
    "https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py\n",
    "\n",
    "**VGG-16** network를 Slim library로 생성한다. 먼저 CNN에 입력으로 들어갈 영상, 클래스 레이블 2개의 placeholder를 정의하고, **CIFAR-10** dataset에 맞게 **VGG-16** 모델의 마지막 fc layer만 수정한다. **tf.contrib.slim.get_variables_to_restore()**을 통해 checkpoint로부터 가져 올 parameters를 정하도록 한다.\n",
    "\n",
    "#### Exercise 1-2\n",
    "vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vgg_16/fc8/squeezed:0\", shape=(100, 10), dtype=float32)\n",
      "===> The list of variables to be restored:\n",
      "vgg_16/conv1/conv1_1/weights\n",
      "vgg_16/conv1/conv1_1/biases\n",
      "vgg_16/conv1/conv1_2/weights\n",
      "vgg_16/conv1/conv1_2/biases\n",
      "vgg_16/conv2/conv2_1/weights\n",
      "vgg_16/conv2/conv2_1/biases\n",
      "vgg_16/conv2/conv2_2/weights\n",
      "vgg_16/conv2/conv2_2/biases\n",
      "vgg_16/conv3/conv3_1/weights\n",
      "vgg_16/conv3/conv3_1/biases\n",
      "vgg_16/conv3/conv3_2/weights\n",
      "vgg_16/conv3/conv3_2/biases\n",
      "vgg_16/conv3/conv3_3/weights\n",
      "vgg_16/conv3/conv3_3/biases\n",
      "vgg_16/conv4/conv4_1/weights\n",
      "vgg_16/conv4/conv4_1/biases\n",
      "vgg_16/conv4/conv4_2/weights\n",
      "vgg_16/conv4/conv4_2/biases\n",
      "vgg_16/conv4/conv4_3/weights\n",
      "vgg_16/conv4/conv4_3/biases\n",
      "vgg_16/conv5/conv5_1/weights\n",
      "vgg_16/conv5/conv5_1/biases\n",
      "vgg_16/conv5/conv5_2/weights\n",
      "vgg_16/conv5/conv5_2/biases\n",
      "vgg_16/conv5/conv5_3/weights\n",
      "vgg_16/conv5/conv5_3/biases\n",
      "vgg_16/fc6/weights\n",
      "vgg_16/fc6/biases\n",
      "vgg_16/fc7/weights\n",
      "vgg_16/fc7/biases\n"
     ]
    }
   ],
   "source": [
    "# input placeholders.\n",
    "images = tf.placeholder(dtype=tf.float32, shape=[batch_size, image_size, image_size, 3],\n",
    "                           name='images')\n",
    "labels = tf.placeholder(dtype=tf.int64, shape=[batch_size], name='labels')\n",
    "\n",
    "# Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "\"\"\"\n",
    "activation_fn=tf.nn.relu,\n",
    "weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "biases_initializer=tf.zeros_initializer()\n",
    "padding='SAME'\n",
    "\"\"\"\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    # 10 classes instead of 1001.\n",
    "    logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=True)\n",
    "print(logits)\n",
    "\n",
    "# Before defining remaining layers (softmax, optimizer), selecting the\n",
    "# variables to be restored\n",
    "exclude_layers = ['vgg_16/fc8']\n",
    "#exclude_layers = ['vgg_16/fc8'] # when discaring only the last classification layer\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=exclude_layers)\n",
    "print('===> The list of variables to be restored:')\n",
    "for i in variables_to_restore: print(i.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용할 loss function과 optimizer를 정한다. 해당 실습에서는 cross_entropy와 softmax를 loss function으로 사용하였고, Gradient Descent알고리즘을 optimizer로 사용해 학습시켰다. **tf.contrib.slim.get_variables_to_restore()**을 통해 학습시킬 레이어를 선택할 수 있다.\n",
    "\n",
    "#### Exercise 1-3\n",
    "variable_to_learn을 이용하여 앞 단의 conv layer는 고정시키고 fc layers만 학습되도록 수정\n",
    "\n",
    "참조: https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(100, 10), dtype=float32)\n",
      "Tensor(\"cross_entropy_per_example/cross_entropy_per_example:0\", shape=(100,), dtype=float32)\n",
      "\n",
      "===> The list of variables to be learned:\n",
      "vgg_16/fc6/weights\n",
      "vgg_16/fc6/biases\n",
      "vgg_16/fc7/weights\n",
      "vgg_16/fc7/biases\n",
      "vgg_16/fc8/weights\n",
      "vgg_16/fc8/biases\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "\n",
    "print(probabilities)\n",
    "print(loss)\n",
    "\n",
    "# select variables to be learned\n",
    "fix_layers = ['vgg_16/conv1', 'vgg_16/conv2', 'vgg_16/conv3', 'vgg_16/conv4', 'vgg_16/conv5']\n",
    "variables_to_learn = slim.get_variables_to_restore(exclude=fix_layers)\n",
    "#variables_to_learn = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "print('\\n===> The list of variables to be learned:')\n",
    "for i in variables_to_learn: print(i.op.name)\n",
    "\n",
    "global_step = int(num_epochs * iteration_per_epoch)\n",
    "decay_step = int(num_epochs_before_decay * iteration_per_epoch)\n",
    "    \n",
    "lr = tf.train.exponential_decay(\n",
    "    learning_rate = initial_learning_rate,\n",
    "    global_step = global_step,\n",
    "    decay_steps = decay_step,\n",
    "    decay_rate = learning_rate_decay_rate,\n",
    "    staircase = True)\n",
    "\n",
    "# Specify the optimizer and create the train op:\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss, var_list=variables_to_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization and Training from scratch\n",
    "**VGG-16** network 모델의 parameters를 Random initialization한 후 **CIFAR-10** dataset으로 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Model parameters\n",
    "save_path = 'cifar10_ramdom-init_checkpoints/cifar10_cnn'\n",
    "if not os.path.exists('cifar10_ramdom-init_checkpoints'): \n",
    "    os.makedirs('cifar10_ramdom-init_checkpoints')\n",
    "    \n",
    "# Train the model\n",
    "saver = tf.train.Saver()\n",
    "for ie in range(num_epochs):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train', (224,224))\n",
    "\n",
    "        # Run the optimizer\n",
    "        _ = sess.run([train_op], feed_dict={images:batch['images'],\n",
    "                                            labels:batch['labels']})\n",
    "\n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if (ii+1) % print_frequency == 0:\n",
    "            batch_loss, batch_prob = sess.run([loss, probabilities], \n",
    "                                             feed_dict={images:batch['images'],\n",
    "                                                        labels:batch['labels']})\n",
    "            pred_labels = np.argmax(batch_prob, axis=1)\n",
    "            batch_loss = np.mean(batch_loss)\n",
    "            batch_acc = np.mean(np.equal(pred_labels, batch['labels']))\n",
    "            print('%d Epoch %d iteration - Loss (%.3f) Accuracy (%.3f)'\n",
    "                      %(ie+1, ii+1, batch_loss, batch_acc))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (ii+1) % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=ie*iteration_per_epoch + ii + 1)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, ie*iteration_per_epoch + ii + 1))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iteration_per_epoch = int(math.floor(loader.get_num_test_examples() / batch_size))\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='cifar10_random-init_checkpoints/')\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))\n",
    "\n",
    "print(iteration_per_epoch)\n",
    "\n",
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Load the checkpoint or initialize the variables\n",
    "saver.restore(sess, save_path=checkpoint_path)\n",
    "print('Model is restored from %s' % checkpoint_path)\n",
    "\n",
    "loader.reset()\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "\n",
    "# Evaluate the model\n",
    "while True:\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(batch_size, 'test', (224,224))\n",
    "    if batch['wrapped']: break\n",
    "\n",
    "    # Compute the correct numbers\n",
    "    batch_prob = sess.run(probabilities, feed_dict={images:batch['images'],\n",
    "                                                      labels:batch['labels']})\n",
    "\n",
    "    pred_labels = np.argmax(batch_prob, axis=1)\n",
    "    batch_correct_num = np.sum(np.equal(pred_labels, batch['labels']))\n",
    "\n",
    "    num_correct += batch_correct_num\n",
    "    num_examples += batch_size\n",
    "    \n",
    "    if (ii+1) % 10 == 0:\n",
    "        print('%d/%d done' % (ii+1, iteration_per_epoch))\n",
    "    ii += 1\n",
    "print('Test accuracy: %.2f%%' % (float(num_correct) / float(num_examples) * 100.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning VGG-16\n",
    "**vgg_models/vgg_16.ckpt** 파일을 읽어와 위에서 정의한 **VGG-16** network의 parameters을 수정한 후 **CIFAR-10** dataset을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vgg_models/vgg_16.ckpt\n",
      "Model is restored from vgg_models/vgg_16.ckpt\n",
      "1 Epoch 10 iteration - Loss (1.151) Accuracy (0.580)\n",
      "1 Epoch 20 iteration - Loss (0.813) Accuracy (0.700)\n",
      "1 Epoch 30 iteration - Loss (0.874) Accuracy (0.700)\n",
      "1 Epoch 40 iteration - Loss (0.772) Accuracy (0.710)\n",
      "1 Epoch 50 iteration - Loss (0.885) Accuracy (0.680)\n",
      "1 Epoch 60 iteration - Loss (0.657) Accuracy (0.780)\n",
      "1 Epoch 70 iteration - Loss (0.623) Accuracy (0.790)\n",
      "1 Epoch 80 iteration - Loss (0.762) Accuracy (0.720)\n",
      "1 Epoch 90 iteration - Loss (0.769) Accuracy (0.780)\n",
      "1 Epoch 100 iteration - Loss (0.645) Accuracy (0.780)\n",
      "1 Epoch 110 iteration - Loss (0.670) Accuracy (0.760)\n",
      "1 Epoch 120 iteration - Loss (0.503) Accuracy (0.790)\n",
      "1 Epoch 130 iteration - Loss (0.516) Accuracy (0.850)\n",
      "1 Epoch 140 iteration - Loss (0.471) Accuracy (0.810)\n",
      "1 Epoch 150 iteration - Loss (0.667) Accuracy (0.760)\n",
      "1 Epoch 160 iteration - Loss (0.676) Accuracy (0.760)\n",
      "1 Epoch 170 iteration - Loss (0.518) Accuracy (0.820)\n",
      "1 Epoch 180 iteration - Loss (0.532) Accuracy (0.800)\n",
      "1 Epoch 190 iteration - Loss (0.368) Accuracy (0.860)\n",
      "1 Epoch 200 iteration - Loss (0.614) Accuracy (0.800)\n",
      "1 Epoch 210 iteration - Loss (0.512) Accuracy (0.860)\n",
      "1 Epoch 220 iteration - Loss (0.777) Accuracy (0.760)\n",
      "1 Epoch 230 iteration - Loss (0.594) Accuracy (0.800)\n",
      "1 Epoch 240 iteration - Loss (0.663) Accuracy (0.760)\n",
      "1 Epoch 250 iteration - Loss (0.328) Accuracy (0.870)\n",
      "1 Epoch 260 iteration - Loss (0.494) Accuracy (0.850)\n",
      "1 Epoch 270 iteration - Loss (0.545) Accuracy (0.800)\n",
      "1 Epoch 280 iteration - Loss (0.491) Accuracy (0.830)\n",
      "1 Epoch 290 iteration - Loss (0.451) Accuracy (0.880)\n",
      "1 Epoch 300 iteration - Loss (0.377) Accuracy (0.890)\n",
      "1 Epoch 310 iteration - Loss (0.512) Accuracy (0.810)\n",
      "1 Epoch 320 iteration - Loss (0.554) Accuracy (0.840)\n",
      "1 Epoch 330 iteration - Loss (0.551) Accuracy (0.780)\n",
      "1 Epoch 340 iteration - Loss (0.460) Accuracy (0.870)\n",
      "1 Epoch 350 iteration - Loss (0.545) Accuracy (0.810)\n",
      "1 Epoch 360 iteration - Loss (0.542) Accuracy (0.820)\n",
      "1 Epoch 370 iteration - Loss (0.553) Accuracy (0.830)\n",
      "1 Epoch 380 iteration - Loss (0.590) Accuracy (0.800)\n",
      "1 Epoch 390 iteration - Loss (0.634) Accuracy (0.740)\n",
      "1 Epoch 400 iteration - Loss (0.421) Accuracy (0.870)\n",
      "1 Epoch 410 iteration - Loss (0.610) Accuracy (0.790)\n",
      "1 Epoch 420 iteration - Loss (0.501) Accuracy (0.850)\n",
      "1 Epoch 430 iteration - Loss (0.684) Accuracy (0.800)\n",
      "1 Epoch 440 iteration - Loss (0.571) Accuracy (0.830)\n",
      "1 Epoch 450 iteration - Loss (0.340) Accuracy (0.880)\n",
      "1 Epoch 460 iteration - Loss (0.584) Accuracy (0.760)\n",
      "1 Epoch 470 iteration - Loss (0.422) Accuracy (0.820)\n",
      "1 Epoch 480 iteration - Loss (0.611) Accuracy (0.820)\n",
      "1 Epoch 490 iteration - Loss (0.445) Accuracy (0.840)\n",
      "1 Epoch 500 iteration - Loss (0.347) Accuracy (0.910)\n",
      "Saved checkpoint cifar10_fine-tuning_checkpoints/cifar10_cnn_500\n",
      "2 Epoch 10 iteration - Loss (0.340) Accuracy (0.880)\n",
      "2 Epoch 20 iteration - Loss (0.287) Accuracy (0.910)\n",
      "2 Epoch 30 iteration - Loss (0.386) Accuracy (0.880)\n",
      "2 Epoch 40 iteration - Loss (0.466) Accuracy (0.830)\n",
      "2 Epoch 50 iteration - Loss (0.385) Accuracy (0.880)\n",
      "2 Epoch 60 iteration - Loss (0.203) Accuracy (0.940)\n",
      "2 Epoch 70 iteration - Loss (0.248) Accuracy (0.910)\n",
      "2 Epoch 80 iteration - Loss (0.384) Accuracy (0.830)\n",
      "2 Epoch 90 iteration - Loss (0.440) Accuracy (0.860)\n",
      "2 Epoch 100 iteration - Loss (0.211) Accuracy (0.940)\n",
      "2 Epoch 110 iteration - Loss (0.240) Accuracy (0.890)\n",
      "2 Epoch 120 iteration - Loss (0.292) Accuracy (0.880)\n",
      "2 Epoch 130 iteration - Loss (0.186) Accuracy (0.920)\n",
      "2 Epoch 140 iteration - Loss (0.253) Accuracy (0.910)\n",
      "2 Epoch 150 iteration - Loss (0.353) Accuracy (0.870)\n",
      "2 Epoch 160 iteration - Loss (0.308) Accuracy (0.890)\n",
      "2 Epoch 170 iteration - Loss (0.238) Accuracy (0.910)\n",
      "2 Epoch 180 iteration - Loss (0.254) Accuracy (0.900)\n",
      "2 Epoch 190 iteration - Loss (0.271) Accuracy (0.930)\n",
      "2 Epoch 200 iteration - Loss (0.357) Accuracy (0.900)\n",
      "2 Epoch 210 iteration - Loss (0.205) Accuracy (0.930)\n",
      "2 Epoch 220 iteration - Loss (0.394) Accuracy (0.860)\n",
      "2 Epoch 230 iteration - Loss (0.318) Accuracy (0.860)\n",
      "2 Epoch 240 iteration - Loss (0.353) Accuracy (0.860)\n",
      "2 Epoch 250 iteration - Loss (0.225) Accuracy (0.920)\n",
      "2 Epoch 260 iteration - Loss (0.293) Accuracy (0.910)\n",
      "2 Epoch 270 iteration - Loss (0.315) Accuracy (0.880)\n",
      "2 Epoch 280 iteration - Loss (0.280) Accuracy (0.920)\n",
      "2 Epoch 290 iteration - Loss (0.150) Accuracy (0.950)\n",
      "2 Epoch 300 iteration - Loss (0.147) Accuracy (0.960)\n",
      "2 Epoch 310 iteration - Loss (0.214) Accuracy (0.920)\n",
      "2 Epoch 320 iteration - Loss (0.277) Accuracy (0.920)\n",
      "2 Epoch 330 iteration - Loss (0.332) Accuracy (0.850)\n",
      "2 Epoch 340 iteration - Loss (0.293) Accuracy (0.910)\n",
      "2 Epoch 350 iteration - Loss (0.232) Accuracy (0.930)\n",
      "2 Epoch 360 iteration - Loss (0.274) Accuracy (0.860)\n",
      "2 Epoch 370 iteration - Loss (0.279) Accuracy (0.910)\n",
      "2 Epoch 380 iteration - Loss (0.324) Accuracy (0.880)\n",
      "2 Epoch 390 iteration - Loss (0.331) Accuracy (0.870)\n",
      "2 Epoch 400 iteration - Loss (0.270) Accuracy (0.900)\n",
      "2 Epoch 410 iteration - Loss (0.353) Accuracy (0.880)\n",
      "2 Epoch 420 iteration - Loss (0.204) Accuracy (0.920)\n",
      "2 Epoch 430 iteration - Loss (0.260) Accuracy (0.920)\n",
      "2 Epoch 440 iteration - Loss (0.265) Accuracy (0.920)\n",
      "2 Epoch 450 iteration - Loss (0.246) Accuracy (0.930)\n",
      "2 Epoch 460 iteration - Loss (0.201) Accuracy (0.960)\n",
      "2 Epoch 470 iteration - Loss (0.222) Accuracy (0.890)\n",
      "2 Epoch 480 iteration - Loss (0.271) Accuracy (0.940)\n",
      "2 Epoch 490 iteration - Loss (0.299) Accuracy (0.880)\n",
      "2 Epoch 500 iteration - Loss (0.137) Accuracy (0.970)\n",
      "Saved checkpoint cifar10_fine-tuning_checkpoints/cifar10_cnn_1000\n",
      "3 Epoch 10 iteration - Loss (0.147) Accuracy (0.930)\n",
      "3 Epoch 20 iteration - Loss (0.144) Accuracy (0.940)\n",
      "3 Epoch 30 iteration - Loss (0.282) Accuracy (0.910)\n",
      "3 Epoch 40 iteration - Loss (0.159) Accuracy (0.920)\n",
      "3 Epoch 50 iteration - Loss (0.144) Accuracy (0.960)\n",
      "3 Epoch 60 iteration - Loss (0.084) Accuracy (0.970)\n",
      "3 Epoch 70 iteration - Loss (0.172) Accuracy (0.920)\n",
      "3 Epoch 80 iteration - Loss (0.178) Accuracy (0.940)\n",
      "3 Epoch 90 iteration - Loss (0.237) Accuracy (0.910)\n",
      "3 Epoch 100 iteration - Loss (0.122) Accuracy (0.960)\n",
      "3 Epoch 110 iteration - Loss (0.106) Accuracy (0.950)\n",
      "3 Epoch 120 iteration - Loss (0.109) Accuracy (0.970)\n",
      "3 Epoch 130 iteration - Loss (0.042) Accuracy (0.990)\n",
      "3 Epoch 140 iteration - Loss (0.099) Accuracy (0.950)\n",
      "3 Epoch 150 iteration - Loss (0.210) Accuracy (0.910)\n",
      "3 Epoch 160 iteration - Loss (0.103) Accuracy (0.970)\n",
      "3 Epoch 170 iteration - Loss (0.125) Accuracy (0.950)\n",
      "3 Epoch 180 iteration - Loss (0.120) Accuracy (0.960)\n",
      "3 Epoch 190 iteration - Loss (0.174) Accuracy (0.930)\n",
      "3 Epoch 200 iteration - Loss (0.099) Accuracy (0.980)\n",
      "3 Epoch 210 iteration - Loss (0.101) Accuracy (0.950)\n",
      "3 Epoch 220 iteration - Loss (0.144) Accuracy (0.940)\n",
      "3 Epoch 230 iteration - Loss (0.206) Accuracy (0.920)\n",
      "3 Epoch 240 iteration - Loss (0.167) Accuracy (0.920)\n",
      "3 Epoch 250 iteration - Loss (0.081) Accuracy (0.990)\n",
      "3 Epoch 260 iteration - Loss (0.083) Accuracy (0.970)\n",
      "3 Epoch 270 iteration - Loss (0.108) Accuracy (0.950)\n",
      "3 Epoch 280 iteration - Loss (0.048) Accuracy (0.980)\n",
      "3 Epoch 290 iteration - Loss (0.059) Accuracy (0.990)\n",
      "3 Epoch 300 iteration - Loss (0.081) Accuracy (0.980)\n",
      "3 Epoch 310 iteration - Loss (0.094) Accuracy (0.960)\n",
      "3 Epoch 320 iteration - Loss (0.210) Accuracy (0.920)\n",
      "3 Epoch 330 iteration - Loss (0.200) Accuracy (0.930)\n",
      "3 Epoch 340 iteration - Loss (0.259) Accuracy (0.920)\n",
      "3 Epoch 350 iteration - Loss (0.185) Accuracy (0.940)\n",
      "3 Epoch 360 iteration - Loss (0.189) Accuracy (0.950)\n",
      "3 Epoch 370 iteration - Loss (0.121) Accuracy (0.930)\n",
      "3 Epoch 380 iteration - Loss (0.210) Accuracy (0.930)\n",
      "3 Epoch 390 iteration - Loss (0.260) Accuracy (0.880)\n",
      "3 Epoch 400 iteration - Loss (0.161) Accuracy (0.950)\n",
      "3 Epoch 410 iteration - Loss (0.170) Accuracy (0.940)\n",
      "3 Epoch 420 iteration - Loss (0.218) Accuracy (0.930)\n",
      "3 Epoch 430 iteration - Loss (0.154) Accuracy (0.960)\n",
      "3 Epoch 440 iteration - Loss (0.103) Accuracy (0.980)\n",
      "3 Epoch 450 iteration - Loss (0.153) Accuracy (0.950)\n",
      "3 Epoch 460 iteration - Loss (0.131) Accuracy (0.940)\n",
      "3 Epoch 470 iteration - Loss (0.092) Accuracy (0.980)\n",
      "3 Epoch 480 iteration - Loss (0.191) Accuracy (0.930)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Epoch 490 iteration - Loss (0.055) Accuracy (0.990)\n",
      "3 Epoch 500 iteration - Loss (0.098) Accuracy (0.950)\n",
      "Saved checkpoint cifar10_fine-tuning_checkpoints/cifar10_cnn_1500\n",
      "4 Epoch 10 iteration - Loss (0.176) Accuracy (0.930)\n",
      "4 Epoch 20 iteration - Loss (0.160) Accuracy (0.920)\n",
      "4 Epoch 30 iteration - Loss (0.076) Accuracy (0.980)\n",
      "4 Epoch 40 iteration - Loss (0.114) Accuracy (0.960)\n",
      "4 Epoch 50 iteration - Loss (0.100) Accuracy (0.980)\n",
      "4 Epoch 60 iteration - Loss (0.029) Accuracy (0.990)\n",
      "4 Epoch 70 iteration - Loss (0.127) Accuracy (0.970)\n",
      "4 Epoch 80 iteration - Loss (0.088) Accuracy (0.980)\n",
      "4 Epoch 90 iteration - Loss (0.095) Accuracy (0.970)\n",
      "4 Epoch 100 iteration - Loss (0.055) Accuracy (0.970)\n",
      "4 Epoch 110 iteration - Loss (0.068) Accuracy (0.970)\n",
      "4 Epoch 120 iteration - Loss (0.129) Accuracy (0.950)\n",
      "4 Epoch 130 iteration - Loss (0.095) Accuracy (0.970)\n",
      "4 Epoch 140 iteration - Loss (0.101) Accuracy (0.980)\n",
      "4 Epoch 150 iteration - Loss (0.149) Accuracy (0.960)\n",
      "4 Epoch 160 iteration - Loss (0.104) Accuracy (0.990)\n",
      "4 Epoch 170 iteration - Loss (0.120) Accuracy (0.960)\n",
      "4 Epoch 180 iteration - Loss (0.082) Accuracy (0.950)\n",
      "4 Epoch 190 iteration - Loss (0.048) Accuracy (0.980)\n",
      "4 Epoch 200 iteration - Loss (0.111) Accuracy (0.940)\n",
      "4 Epoch 210 iteration - Loss (0.045) Accuracy (0.970)\n",
      "4 Epoch 220 iteration - Loss (0.179) Accuracy (0.940)\n",
      "4 Epoch 230 iteration - Loss (0.267) Accuracy (0.910)\n",
      "4 Epoch 240 iteration - Loss (0.097) Accuracy (0.950)\n",
      "4 Epoch 250 iteration - Loss (0.117) Accuracy (0.960)\n",
      "4 Epoch 260 iteration - Loss (0.073) Accuracy (0.970)\n",
      "4 Epoch 270 iteration - Loss (0.059) Accuracy (0.990)\n",
      "4 Epoch 280 iteration - Loss (0.121) Accuracy (0.970)\n",
      "4 Epoch 290 iteration - Loss (0.053) Accuracy (0.990)\n",
      "4 Epoch 300 iteration - Loss (0.125) Accuracy (0.950)\n",
      "4 Epoch 310 iteration - Loss (0.073) Accuracy (0.990)\n",
      "4 Epoch 320 iteration - Loss (0.087) Accuracy (0.980)\n",
      "4 Epoch 330 iteration - Loss (0.120) Accuracy (0.970)\n",
      "4 Epoch 340 iteration - Loss (0.088) Accuracy (0.980)\n",
      "4 Epoch 350 iteration - Loss (0.073) Accuracy (0.970)\n",
      "4 Epoch 360 iteration - Loss (0.136) Accuracy (0.940)\n",
      "4 Epoch 370 iteration - Loss (0.149) Accuracy (0.950)\n",
      "4 Epoch 380 iteration - Loss (0.105) Accuracy (0.980)\n",
      "4 Epoch 390 iteration - Loss (0.160) Accuracy (0.960)\n",
      "4 Epoch 400 iteration - Loss (0.200) Accuracy (0.940)\n",
      "4 Epoch 410 iteration - Loss (0.187) Accuracy (0.960)\n",
      "4 Epoch 420 iteration - Loss (0.137) Accuracy (0.960)\n",
      "4 Epoch 430 iteration - Loss (0.169) Accuracy (0.950)\n",
      "4 Epoch 440 iteration - Loss (0.083) Accuracy (0.980)\n",
      "4 Epoch 450 iteration - Loss (0.095) Accuracy (0.970)\n",
      "4 Epoch 460 iteration - Loss (0.108) Accuracy (0.960)\n",
      "4 Epoch 470 iteration - Loss (0.053) Accuracy (0.980)\n",
      "4 Epoch 480 iteration - Loss (0.073) Accuracy (0.970)\n",
      "4 Epoch 490 iteration - Loss (0.096) Accuracy (0.960)\n",
      "4 Epoch 500 iteration - Loss (0.055) Accuracy (0.990)\n",
      "Saved checkpoint cifar10_fine-tuning_checkpoints/cifar10_cnn_2000\n",
      "5 Epoch 10 iteration - Loss (0.052) Accuracy (0.980)\n",
      "5 Epoch 20 iteration - Loss (0.082) Accuracy (0.960)\n",
      "5 Epoch 30 iteration - Loss (0.172) Accuracy (0.940)\n",
      "5 Epoch 40 iteration - Loss (0.164) Accuracy (0.940)\n",
      "5 Epoch 50 iteration - Loss (0.060) Accuracy (0.970)\n",
      "5 Epoch 60 iteration - Loss (0.097) Accuracy (0.980)\n",
      "5 Epoch 70 iteration - Loss (0.033) Accuracy (0.990)\n",
      "5 Epoch 80 iteration - Loss (0.048) Accuracy (0.990)\n",
      "5 Epoch 90 iteration - Loss (0.263) Accuracy (0.910)\n",
      "5 Epoch 100 iteration - Loss (0.071) Accuracy (0.970)\n",
      "5 Epoch 110 iteration - Loss (0.034) Accuracy (0.990)\n",
      "5 Epoch 120 iteration - Loss (0.085) Accuracy (0.970)\n",
      "5 Epoch 130 iteration - Loss (0.048) Accuracy (0.990)\n",
      "5 Epoch 140 iteration - Loss (0.051) Accuracy (0.980)\n",
      "5 Epoch 150 iteration - Loss (0.048) Accuracy (0.970)\n",
      "5 Epoch 160 iteration - Loss (0.148) Accuracy (0.980)\n",
      "5 Epoch 170 iteration - Loss (0.104) Accuracy (0.970)\n",
      "5 Epoch 180 iteration - Loss (0.056) Accuracy (0.980)\n",
      "5 Epoch 190 iteration - Loss (0.082) Accuracy (0.960)\n",
      "5 Epoch 200 iteration - Loss (0.085) Accuracy (0.960)\n",
      "5 Epoch 210 iteration - Loss (0.005) Accuracy (1.000)\n",
      "5 Epoch 220 iteration - Loss (0.086) Accuracy (0.960)\n",
      "5 Epoch 230 iteration - Loss (0.184) Accuracy (0.960)\n",
      "5 Epoch 240 iteration - Loss (0.096) Accuracy (0.940)\n",
      "5 Epoch 250 iteration - Loss (0.111) Accuracy (0.970)\n",
      "5 Epoch 260 iteration - Loss (0.090) Accuracy (0.990)\n",
      "5 Epoch 270 iteration - Loss (0.065) Accuracy (0.980)\n",
      "5 Epoch 280 iteration - Loss (0.015) Accuracy (0.990)\n",
      "5 Epoch 290 iteration - Loss (0.037) Accuracy (0.980)\n",
      "5 Epoch 300 iteration - Loss (0.030) Accuracy (0.990)\n",
      "5 Epoch 310 iteration - Loss (0.113) Accuracy (0.960)\n",
      "5 Epoch 320 iteration - Loss (0.034) Accuracy (1.000)\n",
      "5 Epoch 330 iteration - Loss (0.065) Accuracy (0.980)\n",
      "5 Epoch 340 iteration - Loss (0.059) Accuracy (0.980)\n",
      "5 Epoch 350 iteration - Loss (0.079) Accuracy (0.970)\n",
      "5 Epoch 360 iteration - Loss (0.152) Accuracy (0.960)\n",
      "5 Epoch 370 iteration - Loss (0.068) Accuracy (0.980)\n",
      "5 Epoch 380 iteration - Loss (0.029) Accuracy (0.990)\n",
      "5 Epoch 390 iteration - Loss (0.079) Accuracy (0.980)\n",
      "5 Epoch 400 iteration - Loss (0.081) Accuracy (0.970)\n",
      "5 Epoch 410 iteration - Loss (0.047) Accuracy (0.980)\n",
      "5 Epoch 420 iteration - Loss (0.043) Accuracy (0.990)\n",
      "5 Epoch 430 iteration - Loss (0.048) Accuracy (0.980)\n",
      "5 Epoch 440 iteration - Loss (0.062) Accuracy (0.960)\n",
      "5 Epoch 450 iteration - Loss (0.044) Accuracy (0.980)\n",
      "5 Epoch 460 iteration - Loss (0.075) Accuracy (0.950)\n",
      "5 Epoch 470 iteration - Loss (0.098) Accuracy (0.990)\n",
      "5 Epoch 480 iteration - Loss (0.132) Accuracy (0.970)\n",
      "5 Epoch 490 iteration - Loss (0.022) Accuracy (0.990)\n",
      "5 Epoch 500 iteration - Loss (0.020) Accuracy (0.990)\n",
      "Saved checkpoint cifar10_fine-tuning_checkpoints/cifar10_cnn_2500\n"
     ]
    }
   ],
   "source": [
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Create the saver with variables to be restored\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "restorer.restore(sess, save_path=checkpoint_path)\n",
    "\n",
    "print('Model is restored from %s' % checkpoint_path)\n",
    "\n",
    "save_path = 'cifar10_fine-tuning_checkpoints/cifar10_cnn'\n",
    "if not os.path.exists('cifar10_fine-tuning_checkpoints'): \n",
    "    os.makedirs('cifar10_fine-tuning_checkpoints')\n",
    "\n",
    "# Train the model\n",
    "saver = tf.train.Saver()\n",
    "for ie in range(num_epochs):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train', (224,224))\n",
    "        \n",
    "        # Run the optimizer\n",
    "        _ = sess.run([train_op], feed_dict={images:batch['images'],\n",
    "                                            labels:batch['labels']})\n",
    "        \n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if (ii+1) % print_frequency == 0:\n",
    "            batch_loss, batch_prob = sess.run([loss, probabilities], \n",
    "                                              feed_dict={images:batch['images'],\n",
    "                                                         labels:batch['labels']})\n",
    "            pred_labels = np.argmax(batch_prob, axis=1)\n",
    "            batch_loss = np.mean(batch_loss)\n",
    "            batch_acc =np.mean(np.equal(pred_labels, batch['labels']))\n",
    "            print('%d Epoch %d iteration - Loss (%.3f) Accuracy (%.3f)'\n",
    "                  %(ie+1, ii+1, batch_loss, batch_acc))\n",
    "            \n",
    "        # Save checkpoint\n",
    "        if (ii+1) % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=ie*iteration_per_epoch + ii + 1)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, ie*iteration_per_epoch + ii + 1))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last checkpoint path is cifar10_fine-tuning_checkpoints/cifar10_cnn-2500\n",
      "INFO:tensorflow:Restoring parameters from cifar10_fine-tuning_checkpoints/cifar10_cnn-2500\n",
      "Model is restored from cifar10_fine-tuning_checkpoints/cifar10_cnn-2500\n",
      "Number of correct data: 85\n",
      "Number of total data: 100\n",
      "Number of correct data: 80\n",
      "Number of total data: 200\n",
      "Number of correct data: 76\n",
      "Number of total data: 300\n",
      "Number of correct data: 83\n",
      "Number of total data: 400\n",
      "Number of correct data: 85\n",
      "Number of total data: 500\n",
      "Number of correct data: 89\n",
      "Number of total data: 600\n",
      "Number of correct data: 90\n",
      "Number of total data: 700\n",
      "Number of correct data: 77\n",
      "Number of total data: 800\n",
      "Number of correct data: 84\n",
      "Number of total data: 900\n",
      "Number of correct data: 87\n",
      "Number of total data: 1000\n",
      "10/100 done\n",
      "Number of correct data: 79\n",
      "Number of total data: 1100\n",
      "Number of correct data: 82\n",
      "Number of total data: 1200\n",
      "Number of correct data: 85\n",
      "Number of total data: 1300\n",
      "Number of correct data: 87\n",
      "Number of total data: 1400\n",
      "Number of correct data: 87\n",
      "Number of total data: 1500\n",
      "Number of correct data: 88\n",
      "Number of total data: 1600\n",
      "Number of correct data: 83\n",
      "Number of total data: 1700\n",
      "Number of correct data: 83\n",
      "Number of total data: 1800\n",
      "Number of correct data: 83\n",
      "Number of total data: 1900\n",
      "Number of correct data: 83\n",
      "Number of total data: 2000\n",
      "20/100 done\n",
      "Number of correct data: 84\n",
      "Number of total data: 2100\n",
      "Number of correct data: 82\n",
      "Number of total data: 2200\n",
      "Number of correct data: 87\n",
      "Number of total data: 2300\n",
      "Number of correct data: 86\n",
      "Number of total data: 2400\n",
      "Number of correct data: 83\n",
      "Number of total data: 2500\n",
      "Number of correct data: 79\n",
      "Number of total data: 2600\n",
      "Number of correct data: 90\n",
      "Number of total data: 2700\n",
      "Number of correct data: 82\n",
      "Number of total data: 2800\n",
      "Number of correct data: 81\n",
      "Number of total data: 2900\n",
      "Number of correct data: 80\n",
      "Number of total data: 3000\n",
      "30/100 done\n",
      "Number of correct data: 89\n",
      "Number of total data: 3100\n",
      "Number of correct data: 81\n",
      "Number of total data: 3200\n",
      "Number of correct data: 82\n",
      "Number of total data: 3300\n",
      "Number of correct data: 76\n",
      "Number of total data: 3400\n",
      "Number of correct data: 79\n",
      "Number of total data: 3500\n",
      "Number of correct data: 85\n",
      "Number of total data: 3600\n",
      "Number of correct data: 79\n",
      "Number of total data: 3700\n",
      "Number of correct data: 78\n",
      "Number of total data: 3800\n",
      "Number of correct data: 83\n",
      "Number of total data: 3900\n",
      "Number of correct data: 85\n",
      "Number of total data: 4000\n",
      "40/100 done\n",
      "Number of correct data: 86\n",
      "Number of total data: 4100\n",
      "Number of correct data: 88\n",
      "Number of total data: 4200\n",
      "Number of correct data: 91\n",
      "Number of total data: 4300\n",
      "Number of correct data: 86\n",
      "Number of total data: 4400\n",
      "Number of correct data: 86\n",
      "Number of total data: 4500\n",
      "Number of correct data: 79\n",
      "Number of total data: 4600\n",
      "Number of correct data: 88\n",
      "Number of total data: 4700\n",
      "Number of correct data: 82\n",
      "Number of total data: 4800\n",
      "Number of correct data: 86\n",
      "Number of total data: 4900\n",
      "Number of correct data: 82\n",
      "Number of total data: 5000\n",
      "50/100 done\n",
      "Number of correct data: 81\n",
      "Number of total data: 5100\n",
      "Number of correct data: 89\n",
      "Number of total data: 5200\n",
      "Number of correct data: 87\n",
      "Number of total data: 5300\n",
      "Number of correct data: 85\n",
      "Number of total data: 5400\n",
      "Number of correct data: 84\n",
      "Number of total data: 5500\n",
      "Number of correct data: 85\n",
      "Number of total data: 5600\n",
      "Number of correct data: 83\n",
      "Number of total data: 5700\n",
      "Number of correct data: 85\n",
      "Number of total data: 5800\n",
      "Number of correct data: 80\n",
      "Number of total data: 5900\n",
      "Number of correct data: 87\n",
      "Number of total data: 6000\n",
      "60/100 done\n",
      "Number of correct data: 82\n",
      "Number of total data: 6100\n",
      "Number of correct data: 86\n",
      "Number of total data: 6200\n",
      "Number of correct data: 84\n",
      "Number of total data: 6300\n",
      "Number of correct data: 86\n",
      "Number of total data: 6400\n",
      "Number of correct data: 83\n",
      "Number of total data: 6500\n",
      "Number of correct data: 74\n",
      "Number of total data: 6600\n",
      "Number of correct data: 84\n",
      "Number of total data: 6700\n",
      "Number of correct data: 83\n",
      "Number of total data: 6800\n",
      "Number of correct data: 82\n",
      "Number of total data: 6900\n",
      "Number of correct data: 77\n",
      "Number of total data: 7000\n",
      "70/100 done\n",
      "Number of correct data: 87\n",
      "Number of total data: 7100\n",
      "Number of correct data: 86\n",
      "Number of total data: 7200\n",
      "Number of correct data: 87\n",
      "Number of total data: 7300\n",
      "Number of correct data: 84\n",
      "Number of total data: 7400\n",
      "Number of correct data: 76\n",
      "Number of total data: 7500\n",
      "Number of correct data: 85\n",
      "Number of total data: 7600\n",
      "Number of correct data: 71\n",
      "Number of total data: 7700\n",
      "Number of correct data: 85\n",
      "Number of total data: 7800\n",
      "Number of correct data: 81\n",
      "Number of total data: 7900\n",
      "Number of correct data: 81\n",
      "Number of total data: 8000\n",
      "80/100 done\n",
      "Number of correct data: 88\n",
      "Number of total data: 8100\n",
      "Number of correct data: 87\n",
      "Number of total data: 8200\n",
      "Number of correct data: 82\n",
      "Number of total data: 8300\n",
      "Number of correct data: 83\n",
      "Number of total data: 8400\n",
      "Number of correct data: 77\n",
      "Number of total data: 8500\n",
      "Number of correct data: 80\n",
      "Number of total data: 8600\n",
      "Number of correct data: 81\n",
      "Number of total data: 8700\n",
      "Number of correct data: 82\n",
      "Number of total data: 8800\n",
      "Number of correct data: 89\n",
      "Number of total data: 8900\n",
      "Number of correct data: 83\n",
      "Number of total data: 9000\n",
      "90/100 done\n",
      "Number of correct data: 85\n",
      "Number of total data: 9100\n",
      "Number of correct data: 86\n",
      "Number of total data: 9200\n",
      "Number of correct data: 82\n",
      "Number of total data: 9300\n",
      "Number of correct data: 80\n",
      "Number of total data: 9400\n",
      "Number of correct data: 86\n",
      "Number of total data: 9500\n",
      "Number of correct data: 81\n",
      "Number of total data: 9600\n",
      "Number of correct data: 84\n",
      "Number of total data: 9700\n",
      "Number of correct data: 84\n",
      "Number of total data: 9800\n",
      "Number of correct data: 83\n",
      "Number of total data: 9900\n",
      "Number of correct data: 82\n",
      "Number of total data: 10000\n",
      "100/100 done\n",
      "Test accuracy: 83.36%\n"
     ]
    }
   ],
   "source": [
    "iteration_per_epoch = int(math.floor(loader.get_num_test_examples() / batch_size))\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='cifar10_fine-tuning_checkpoints/')\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))\n",
    "\n",
    "# Open the session\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Load the checkpoint or initialize the variables\n",
    "saver.restore(sess, save_path=checkpoint_path)\n",
    "print('Model is restored from %s' % checkpoint_path)\n",
    "\n",
    "loader.reset()\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "ii=0\n",
    "\n",
    "# Evaluate the model\n",
    "while True:\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(batch_size, 'test', (224,224))\n",
    "    if batch['wrapped']: break\n",
    "\n",
    "    # Compute the correct numbers\n",
    "    batch_prob = sess.run(probabilities, feed_dict={images:batch['images'],\n",
    "                                                      labels:batch['labels']})\n",
    "\n",
    "    pred_labels = np.argmax(batch_prob, axis=1)\n",
    "    batch_correct_num = np.sum(np.equal(pred_labels, batch['labels']))\n",
    "    \n",
    "    num_correct += batch_correct_num\n",
    "    num_examples += batch_size\n",
    "    \n",
    "    #print('Number of correct data: %d' % batch_correct_num)\n",
    "    #print('Number of total data: %d' % num_examples)\n",
    "    \n",
    "    if (ii+1) % 10 == 0:\n",
    "        print('%d/%d done' % (ii+1, iteration_per_epoch))\n",
    "    ii += 1\n",
    "    \n",
    "print('Test accuracy: %.2f%%' % (float(num_correct) / float(num_examples) * 100.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Exercise 1\n",
    "위 코드를 다음과 같은 내용이 될 수 있도록 수정하도록 한다.\n",
    "1. 학습 횟수 30회, 초기 learning_rate 0.01, 매 10회 학습 마다 learning_rate은 20%로 감소\n",
    "2. vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정\n",
    "3. variable_to_learn을 이용하여 앞 단의 conv layer는 고정시키고 fc layers만 학습되도록 수정\n",
    "\n",
    "### Exercise 2\n",
    "아래 코드는 **/models/research/slim/nets/vgg.py**에 정의된 vgg-16, vgg-19 네트워크의 정의이다. vgg network의 구조와 아래 코드를 참고하여 vgg-postech 네트워크를 구현해보록 한다.\n",
    "\n",
    "![VGG-network](../vgg-network.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_arg_scope(weight_decay=0.0005):\n",
    "  \"\"\"Defines the VGG arg scope.\n",
    "\n",
    "  Args:\n",
    "    weight_decay: The l2 regularization coefficient.\n",
    "\n",
    "  Returns:\n",
    "    An arg_scope.\n",
    "  \"\"\"\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "                      biases_initializer=tf.zeros_initializer()):\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:\n",
    "      return arg_sc\n",
    "\n",
    "def vgg_16(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_16',\n",
    "           fc_conv_padding='VALID'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                            activation_fn=None,\n",
    "                            normalizer_fn=None,\n",
    "                            scope='fc8')\n",
    "            \n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = net\n",
    "            return net, end_points\n",
    "\n",
    "def vgg_19(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_19',\n",
    "           fc_conv_padding='VALID'):\n",
    "\n",
    "    with tf.variable_scope(scope, 'vgg_19', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                               scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                               scope='dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                              activation_fn=None,\n",
    "                              normalizer_fn=None,\n",
    "                              scope='fc8')\n",
    "            \n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = net\n",
    "            return net, end_points\n",
    "        \n",
    "        \n",
    "#TODO: implement VGG-POSTECH network\n",
    "def vgg_postech(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_postech',\n",
    "           fc_conv_padding='VALID'):\n",
    "    with tf.variable_scope(scope, 'vgg_postech', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        #TODO : implement VGG-postech\n",
    "        \n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "        end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        if spatial_squeeze:\n",
    "            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "            end_points[sc.name + '/fc8'] = net\n",
    "        return net, end_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
