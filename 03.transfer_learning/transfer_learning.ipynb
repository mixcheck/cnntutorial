{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow-Slim image classification model library\n",
    "\n",
    "git clone https://github.com/tensorflow/models/\n",
    "\n",
    "**TensorFlow-Slim**은 AlexNet, VGG, ResNet, Inception과 같이 image classification에 사용되는 Deep Learning CNN 모델을 제공하고 있다. CNN 모델 뿐만 아니라 여러 Datasets(ImageNet, CIFAR-10, MNIST 등)도 제공하고 있고 이를 이용한 학습 및 실험 코드도 제공하고 있다. 그리고 각 CNN 모델을 ImageNet 데이터로 학습한 Pre-trained 모델도 제공하여 새로운 Datasets에 대한 Fine-tuning도 가능하게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0,'../models/research/slim')\n",
    "from nets import vgg\n",
    "from datasets import cifar10\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "from utils import *\n",
    "from cifar10_loader import CIFAR10_loader\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Information\n",
    "VGG network는 입력 영상으로 224x224의 image를 받는다. 이번 실습에서는 **CIFAR-10**을 사용하므로 num_classes를 10으로 정의한다. 매 iteration 마다 100개의 images를 학습시킬 것이므로 batch_size는 100이 된다. 총 epoch은 10회 수행하고, (**CIFAR-10** training data 50000개 기준 약 3시간 소요) 매 50번의 iteration마다 network의 parameters를 저장한다.\n",
    "\n",
    "learning rate은 초기에 0.001로 정의하고 5 epoch마다 이 값은 1/10로 줄어든다. ImageNet으로 학습된 **VGG-16** network의 parameters는 **vgg_models/vgg_16.ckpt**이다.\n",
    "\n",
    "#### Exercise 1-1\n",
    "학습 횟수 30회, 초기 learning_rate 0.01, 매 10회 학습 마다 learning_rate은 20%로 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 224 # input image size of VGG network\n",
    "num_classes = 10 # CIFAR-10 number of classes\n",
    "batch_size = 100 # number of images per training iteration\n",
    "\n",
    "num_epochs = 10 # number of training epoch\n",
    "save_checkpoint_frequency = 50 # frequency of saving checkpoints\n",
    "print_frequency = 50\n",
    "\n",
    "initial_learning_rate = 0.001 # initial learning rate for optimizer\n",
    "num_epochs_before_decay=5\n",
    "learning_rate_decay_rate = 0.1 # decay rate for learning rate\n",
    "\n",
    "checkpoint_path = 'vgg_models/vgg_16.ckpt' # Pre-trained VGG-16 checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 Dataset\n",
    "**CIFAR-10** dataset은 32x32 사이즈의 이미지들로 airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck으로 이루어져있다. 각 클래스 별 6천장씩 구성되어 있으며 이중 50000장이 training에 사용되고 10000장이 test에 사용된다. TF-Slim library에서 제공하는 코드를 이용하여 현재 작업중인 폴더의 하위 폴더에 cifar-10 dataset을 저장한다.\n",
    "\n",
    "*CIFAR-10 download link*: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Finished\n",
      "50000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd()\n",
    "data_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "maybe_download_and_extract(data_url, data_dir, 'cifar-10-batches')\n",
    "\n",
    "loader = CIFAR10_loader()\n",
    "class_names = loader.get_class_names()\n",
    "\n",
    "# Model parameters\n",
    "save_path = 'cifar10_checkpoints/cifar10_cnn'\n",
    "if not os.path.exists('cifar10_checkpoints'): os.makedirs('cifar10_checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained model (vgg-16)\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/slim\n",
    "\n",
    "TF-Slim github를 보면 ImageNet으로 학습된 Inception, Resnet, VGG 등 다양한 모델들의 checkpoints가 제공된다. 먼저 오늘 실습에 사용될 **VGG-16**의 checkpoint를 다운 받는다.\n",
    "\n",
    "#### Exercise 1-2\n",
    "vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'vgg_models'\n",
    "model_url = 'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz'\n",
    "maybe_download_and_extract(model_url, model_dir, 'vgg_16.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vgg-16 Model\n",
    "\n",
    "https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py\n",
    "\n",
    "**VGG-16** network를 Slim library로 생성한다. 먼저 CNN에 입력으로 들어갈 영상, 클래스 명 2개의 placeholder를 정의하고, **CIFAR-10** dataset에 맞게 **VGG-16** 모델의 마지막 fc layer만 수정한다. **tf.contrib.slim.get_variables_to_restore()**을 통해 checkpoint로부터 가져 올 parameters를 정하도록 한다.\n",
    "\n",
    "#### Exercise 1-2\n",
    "vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vgg_16/fc8/squeezed:0\", shape=(100, 10), dtype=float32)\n",
      "===> The list of variables to be restored:\n",
      "vgg_16/conv1/conv1_1/weights\n",
      "vgg_16/conv1/conv1_1/biases\n",
      "vgg_16/conv1/conv1_2/weights\n",
      "vgg_16/conv1/conv1_2/biases\n",
      "vgg_16/conv2/conv2_1/weights\n",
      "vgg_16/conv2/conv2_1/biases\n",
      "vgg_16/conv2/conv2_2/weights\n",
      "vgg_16/conv2/conv2_2/biases\n",
      "vgg_16/conv3/conv3_1/weights\n",
      "vgg_16/conv3/conv3_1/biases\n",
      "vgg_16/conv3/conv3_2/weights\n",
      "vgg_16/conv3/conv3_2/biases\n",
      "vgg_16/conv3/conv3_3/weights\n",
      "vgg_16/conv3/conv3_3/biases\n",
      "vgg_16/conv4/conv4_1/weights\n",
      "vgg_16/conv4/conv4_1/biases\n",
      "vgg_16/conv4/conv4_2/weights\n",
      "vgg_16/conv4/conv4_2/biases\n",
      "vgg_16/conv4/conv4_3/weights\n",
      "vgg_16/conv4/conv4_3/biases\n",
      "vgg_16/conv5/conv5_1/weights\n",
      "vgg_16/conv5/conv5_1/biases\n",
      "vgg_16/conv5/conv5_2/weights\n",
      "vgg_16/conv5/conv5_2/biases\n",
      "vgg_16/conv5/conv5_3/weights\n",
      "vgg_16/conv5/conv5_3/biases\n",
      "vgg_16/fc6/weights\n",
      "vgg_16/fc6/biases\n",
      "vgg_16/fc7/weights\n",
      "vgg_16/fc7/biases\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "# input placeholders.\n",
    "images = tf.placeholder(dtype=tf.float32, shape=[batch_size, image_size, image_size, 3],\n",
    "                           name='images')\n",
    "labels = tf.placeholder(dtype=tf.int64, shape=[batch_size], name='labels')\n",
    "\n",
    "# Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "\"\"\"\n",
    "activation_fn=tf.nn.relu,\n",
    "weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "biases_initializer=tf.zeros_initializer()\n",
    "padding='SAME'\n",
    "\"\"\"\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    # 10 classes instead of 1001.\n",
    "    logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=True)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(images,\n",
    "           num_classes=num_classes,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_16',\n",
    "           fc_conv_padding='VALID') as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            logits = slim.repeat(images, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            logits = slim.max_pool2d(logits, [2, 2], scope='pool1')\n",
    "            logits = slim.repeat(logits, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            logits = slim.max_pool2d(logits, [2, 2], scope='pool2')\n",
    "            logits = slim.repeat(logits, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            logits = slim.max_pool2d(logits, [2, 2], scope='pool3')\n",
    "            logits = slim.repeat(logits, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            logits = slim.max_pool2d(logits, [2, 2], scope='pool4')\n",
    "            logits = slim.repeat(logits, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            logits = slim.max_pool2d(logits, [2, 2], scope='pool5')\n",
    "            logits = slim.conv2d(logits, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            logits = slim.dropout(logits, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout6')\n",
    "            logits = slim.conv2d(logits, 4096, [1, 1], scope='fc7')\n",
    "            logits = slim.dropout(logits, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "            logits = slim.conv2d(logits, num_classes, [1, 1],\n",
    "                            activation_fn=None,\n",
    "                            normalizer_fn=None,\n",
    "                            scope='fc8')\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                logits = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = logits\n",
    "    \"\"\"\n",
    "print(logits)\n",
    "\n",
    "# Before defining remaining layers (softmax, optimizer), selecting the\n",
    "# variables to be restored\n",
    "exclude_layers = ['vgg_16/fc8']\n",
    "#exclude_layers = ['vgg_16/fc8'] # when discaring only the last classification layer\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=exclude_layers)\n",
    "print('===> The list of variables to be restored:')\n",
    "for i in variables_to_restore: print(i.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용할 loss function과 parameters를 수정할 optimizer를 정한다. 해당 실습에서는 cross_entropy와 softmax를 loss function으로 사용하였고, Gradient Descent알고리즘을 optimizer로 사용해 학습시켰다. **tf.contrib.slim.get_variables_to_restore()**을 통해 학습시킬 레이어를 선택할 수 있다.\n",
    "\n",
    "#### Exercise 1-3\n",
    "variable_to_learn을 이용하여 앞 단의 conv layer는 고정시키고 fc layers만 학습되도록 수정\n",
    "\n",
    "참조: https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> The list of variables to be learned:\n",
      "vgg_16/conv1/conv1_1/weights\n",
      "vgg_16/conv1/conv1_1/biases\n",
      "vgg_16/conv1/conv1_2/weights\n",
      "vgg_16/conv1/conv1_2/biases\n",
      "vgg_16/conv2/conv2_1/weights\n",
      "vgg_16/conv2/conv2_1/biases\n",
      "vgg_16/conv2/conv2_2/weights\n",
      "vgg_16/conv2/conv2_2/biases\n",
      "vgg_16/conv3/conv3_1/weights\n",
      "vgg_16/conv3/conv3_1/biases\n",
      "vgg_16/conv3/conv3_2/weights\n",
      "vgg_16/conv3/conv3_2/biases\n",
      "vgg_16/conv3/conv3_3/weights\n",
      "vgg_16/conv3/conv3_3/biases\n",
      "vgg_16/conv4/conv4_1/weights\n",
      "vgg_16/conv4/conv4_1/biases\n",
      "vgg_16/conv4/conv4_2/weights\n",
      "vgg_16/conv4/conv4_2/biases\n",
      "vgg_16/conv4/conv4_3/weights\n",
      "vgg_16/conv4/conv4_3/biases\n",
      "vgg_16/conv5/conv5_1/weights\n",
      "vgg_16/conv5/conv5_1/biases\n",
      "vgg_16/conv5/conv5_2/weights\n",
      "vgg_16/conv5/conv5_2/biases\n",
      "vgg_16/conv5/conv5_3/weights\n",
      "vgg_16/conv5/conv5_3/biases\n",
      "vgg_16/fc6/weights\n",
      "vgg_16/fc6/biases\n",
      "vgg_16/fc7/weights\n",
      "vgg_16/fc7/biases\n",
      "vgg_16/fc8/weights\n",
      "vgg_16/fc8/biases\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "\n",
    "# select variables to be learned\n",
    "variables_to_learn = slim.get_variables_to_restore()\n",
    "#variables_to_learn = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "print('\\n===> The list of variables to be learned:')\n",
    "for i in variables_to_learn: print(i.op.name)\n",
    "\n",
    "decay_step = int(num_epochs_before_decay * iteration_per_epoch)\n",
    "global_step = int(num_epochs * iteration_per_epoch)\n",
    "\n",
    "lr = tf.train.exponential_decay(\n",
    "learning_rate = initial_learning_rate,\n",
    "global_step = global_step,\n",
    "decay_steps = decay_step,\n",
    "decay_rate = learning_rate_decay_rate,\n",
    "staircase = True)\n",
    "\n",
    "# Specify the optimizer and create the train op:\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss, var_list=variables_to_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization and Training from scratch\n",
    "**VGG-16** network 모델의 parameters를 Random initialization한 후 **CIFAR-10** dataset으로 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "iteration_per_epoch = int(math.floor(loader.get_num_train_examples() / batch_size))\n",
    "\n",
    "# Train the model\n",
    "saver = tf.train.Saver()\n",
    "for ie in range(num_epochs):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train', (224,224))\n",
    "\n",
    "        # Run the optimizer\n",
    "        _ = sess.run([train_op], feed_dict={images:batch['images'],\n",
    "                                            labels:batch['labels']})\n",
    "\n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if (ii+1) % print_frequency == 0:\n",
    "            batch_loss, batch_prob = sess.run([loss, probabilities], \n",
    "                                             feed_dict={images:batch['images'],\n",
    "                                                        labels:batch['labels']})\n",
    "            pred_labels = np.argmax(batch_prob, axis=1)\n",
    "            batch_loss = np.mean(batch_loss)\n",
    "            batch_acc = np.mean(np.equal(pred_labels, batch['labels']))\n",
    "            print('%d Epoch %d iteration - Loss (%.3f) Accuracy (%.3f)'\n",
    "                      %(ie+1, ii+1, batch_loss, batch_acc))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (ii+1) % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=ie*iteration_per_epoch + ii + 1)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, ie*iteration_per_epoch + ii + 1))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning VGG-16\n",
    "**vgg_models/vgg_16.ckpt** 파일을 읽어와 위에서 정의한 **VGG-16** network의 parameters을 수정한 후 **CIFAR-10** dataset을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vgg_models/vgg_16.ckpt\n",
      "1 Epoch 50 iteration - Loss (1.607) Accuracy (0.470)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_50\n",
      "1 Epoch 100 iteration - Loss (0.976) Accuracy (0.660)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_100\n",
      "1 Epoch 150 iteration - Loss (1.113) Accuracy (0.600)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_150\n",
      "1 Epoch 200 iteration - Loss (0.903) Accuracy (0.680)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_200\n",
      "1 Epoch 250 iteration - Loss (0.540) Accuracy (0.810)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_250\n",
      "1 Epoch 300 iteration - Loss (0.434) Accuracy (0.840)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_300\n",
      "1 Epoch 350 iteration - Loss (0.580) Accuracy (0.820)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_350\n",
      "1 Epoch 400 iteration - Loss (0.474) Accuracy (0.820)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_400\n",
      "1 Epoch 450 iteration - Loss (0.576) Accuracy (0.770)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_450\n",
      "1 Epoch 500 iteration - Loss (0.429) Accuracy (0.840)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_500\n",
      "2 Epoch 50 iteration - Loss (0.546) Accuracy (0.830)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_550\n",
      "2 Epoch 100 iteration - Loss (0.404) Accuracy (0.860)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_600\n",
      "2 Epoch 150 iteration - Loss (0.495) Accuracy (0.850)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_650\n",
      "2 Epoch 200 iteration - Loss (0.328) Accuracy (0.880)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_700\n",
      "2 Epoch 250 iteration - Loss (0.223) Accuracy (0.940)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_750\n",
      "2 Epoch 300 iteration - Loss (0.268) Accuracy (0.900)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_800\n",
      "2 Epoch 350 iteration - Loss (0.364) Accuracy (0.900)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_850\n",
      "2 Epoch 400 iteration - Loss (0.241) Accuracy (0.900)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_900\n",
      "2 Epoch 450 iteration - Loss (0.282) Accuracy (0.890)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_950\n",
      "2 Epoch 500 iteration - Loss (0.208) Accuracy (0.940)\n",
      "Saved checkpoint cifar10_finetuning_checkpoints/cifar10_cnn_1000\n"
     ]
    }
   ],
   "source": [
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Create the saver with variables to be restored\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "restorer.restore(sess, save_path=checkpoint_path)\n",
    "\n",
    "loader.reset()\n",
    "\n",
    "ii = 1\n",
    "ie = 1\n",
    "iteration_per_epoch = int(math.floor(loader.get_num_train_examples() / batch_size))\n",
    "\n",
    "save_path = 'cifar10_finetuning_checkpoints/cifar10_cnn'\n",
    "if not os.path.exists('cifar10_finetuning_checkpoints'): os.makedirs('cifar10_finetuning_checkpoints')\n",
    "\n",
    "# Train the model\n",
    "saver = tf.train.Saver()\n",
    "for ie in range(2):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train', (224,224))\n",
    "\n",
    "        # Run the optimizer\n",
    "        _ = sess.run([train_op], feed_dict={images:batch['images'],\n",
    "                                            labels:batch['labels']})\n",
    "\n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if (ii+1) % print_frequency == 0:\n",
    "            batch_loss, batch_prob = sess.run([loss, probabilities], \n",
    "                                             feed_dict={images:batch['images'],\n",
    "                                                        labels:batch['labels']})\n",
    "            pred_labels = np.argmax(batch_prob, axis=1)\n",
    "            batch_loss = np.mean(batch_loss)\n",
    "            batch_acc =np.mean(np.equal(pred_labels, batch['labels']))\n",
    "            print('%d Epoch %d iteration - Loss (%.3f) Accuracy (%.3f)'\n",
    "                      %(ie+1, ii+1, batch_loss, batch_acc))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (ii+1) % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=ie*iteration_per_epoch + ii + 1)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, ie*iteration_per_epoch + ii + 1))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last checkpoint path is cifar10_finetuning_checkpoints/cifar10_cnn-1000\n",
      "100\n",
      "INFO:tensorflow:Restoring parameters from cifar10_finetuning_checkpoints/cifar10_cnn-1000\n",
      "Model is restored from cifar10_finetuning_checkpoints/cifar10_cnn-1000\n",
      "10/100 done\n",
      "20/100 done\n",
      "30/100 done\n",
      "40/100 done\n",
      "50/100 done\n",
      "60/100 done\n",
      "70/100 done\n",
      "80/100 done\n",
      "90/100 done\n",
      "100/100 done\n",
      "Test accuracy: 85.33%\n"
     ]
    }
   ],
   "source": [
    "iteration_per_epoch = int(math.floor(loader.get_num_test_examples() / batch_size))\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='cifar10_finetuning_checkpoints/')\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))\n",
    "\n",
    "print(iteration_per_epoch)\n",
    "\n",
    "# Open the session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Load the checkpoint or initialize the variables\n",
    "saver.restore(sess, save_path=checkpoint_path)\n",
    "print('Model is restored from %s' % checkpoint_path)\n",
    "\n",
    "loader.reset()\n",
    "ii = 1\n",
    "num_correct = 0\n",
    "num_examples = 0\n",
    "\n",
    "# Evaluate the model\n",
    "while True:\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(batch_size, 'test', (224,224))\n",
    "    if batch['wrapped']: break\n",
    "\n",
    "    # Compute the correct numbers\n",
    "    batch_prob = sess.run(probabilities, feed_dict={images:batch['images'],\n",
    "                                                      labels:batch['labels']})\n",
    "\n",
    "    pred_labels = np.argmax(batch_prob, axis=1)\n",
    "    batch_correct_num = np.sum(np.equal(pred_labels, batch['labels']))\n",
    "\n",
    "    num_correct += batch_correct_num\n",
    "    num_examples += batch_size\n",
    "    \n",
    "    if (ii+1) % 10 == 0:\n",
    "        print('%d/%d done' % (ii+1, iteration_per_epoch))\n",
    "    ii += 1\n",
    "print('Test accuracy: %.2f%%' % (float(num_correct) / float(num_examples) * 100.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Exercise 1\n",
    "위 코드를 다음과 같은 내용이 될 수 있도록 수정하도록 한다.\n",
    "1. 학습 횟수 30회, 초기 learning_rate 0.01, 매 10회 학습 마다 learning_rate은 20%로 감소\n",
    "2. vgg-19 network로 pre-trained model을 읽어와 학습할 수 있도록 수정\n",
    "3. variable_to_learn을 이용하여 앞 단의 conv layer는 고정시키고 fc layers만 학습되도록 수정\n",
    "\n",
    "### Exercise 2\n",
    "아래 코드는 **/models/research/slim/nets/vgg.py**에 정의된 vgg-16, vgg-19 네트워크의 정의이다. vgg network의 구조와 아래 코드를 참고하여 vgg-postech 네트워크를 구현해보록 한다.\n",
    "\n",
    "![VGG-network](../vgg-network.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_arg_scope(weight_decay=0.0005):\n",
    "  \"\"\"Defines the VGG arg scope.\n",
    "\n",
    "  Args:\n",
    "    weight_decay: The l2 regularization coefficient.\n",
    "\n",
    "  Returns:\n",
    "    An arg_scope.\n",
    "  \"\"\"\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "                      biases_initializer=tf.zeros_initializer()):\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:\n",
    "      return arg_sc\n",
    "\n",
    "def vgg_16(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_16',\n",
    "           fc_conv_padding='VALID'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                            activation_fn=None,\n",
    "                            normalizer_fn=None,\n",
    "                            scope='fc8')\n",
    "            \n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = net\n",
    "            return net, end_points\n",
    "\n",
    "def vgg_19(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_19',\n",
    "           fc_conv_padding='VALID'):\n",
    "\n",
    "    with tf.variable_scope(scope, 'vgg_19', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                               scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                               scope='dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                              activation_fn=None,\n",
    "                              normalizer_fn=None,\n",
    "                              scope='fc8')\n",
    "            \n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = net\n",
    "            return net, end_points\n",
    "        \n",
    "        \n",
    "#TODO: implement VGG-POSTECH network\n",
    "def vgg_postech(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_postech',\n",
    "           fc_conv_padding='VALID'):\n",
    "    with tf.variable_scope(scope, 'vgg_postech', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        #TODO : implement VGG-postech\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name + '/fc8'] = net\n",
    "            return net, end_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
